{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oy7tZ5F73tfy"
      },
      "source": [
        "## Get Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBEbEeKnkOPb",
        "outputId": "f49c27c1-26bf-45dd-b6c7-5f07db847e27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "c6EvzBjC1Mn7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/clemente/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xml.etree.ElementTree as ET\n",
        "import matplotlib.pyplot as plt\n",
        "# import sklearn.feature_extraction.text as sk_text\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.models import load_model\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from tensorflow.keras.callbacks import EarlyStopping\n",
        "# from tensorflow.keras.layers import Dense\n",
        "# from sklearn import metrics\n",
        "\n",
        "import torch\n",
        "# !pip install transformers\n",
        "# !pip install -U tensorflow-text==2.14.0\n",
        "from transformers import AutoTokenizer, TFBertTokenizer, BertModel\n",
        "import torch\n",
        "\n",
        "\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TS_tmlYy1TMV"
      },
      "outputs": [],
      "source": [
        "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
        "    if mean is None:\n",
        "        mean = df[name].mean()\n",
        "\n",
        "    if sd is None:\n",
        "        sd = df[name].std()\n",
        "\n",
        "    df[name] = (df[name] - mean) / sd\n",
        "\n",
        "def chart_regression(pred,y,sort=True):\n",
        "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
        "    if sort:\n",
        "        t.sort_values(by=['y'],inplace=True)\n",
        "    a = plt.plot(t['y'].tolist(),label='expected')\n",
        "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
        "    plt.ylabel('output')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def encode_text_dummy(df, name):\n",
        "    dummies = pd.get_dummies(df[name])\n",
        "    for x in dummies.columns:\n",
        "        dummy_name = \"{}-{}\".format(name, x)\n",
        "        df[dummy_name] = dummies[x]\n",
        "    df.drop(name, axis=1, inplace=True)\n",
        "\n",
        "def xml_to_df(xml):\n",
        "  xtree = ET.parse(xml)\n",
        "  xroot = xtree.getroot()\n",
        "\n",
        "  rows = []\n",
        "\n",
        "  for node in xroot:\n",
        "    rows.append(node.attrib)\n",
        "\n",
        "  return pd.DataFrame(rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3v5KTGh9jvlb"
      },
      "outputs": [],
      "source": [
        "dataset = os.path.join(\"myPosts.xml\")\n",
        "dataset = xml_to_df(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Z_p4jMQcjzFE"
      },
      "outputs": [],
      "source": [
        "df = dataset.drop(columns=['CreationDate',\n",
        "                            'OwnerUserId',\n",
        "                            'LastEditorUserId',\n",
        "                            'LastEditDate',\n",
        "                            'LastActivityDate',\n",
        "                            'Title',\n",
        "                            'Tags',\n",
        "                            'AnswerCount',\n",
        "                            'ContentLicense',\n",
        "                            'ParentId',\n",
        "                            'ClosedDate',\n",
        "                            'CommunityOwnedDate',\n",
        "                            'LastEditorDisplayName',\n",
        "                            'OwnerDisplayName',\n",
        "                            'FavoriteCount',\n",
        "                            'CommentCount',\n",
        "                            'ViewCount',\n",
        "                            'AcceptedAnswerId',\n",
        "                            'Id'\n",
        "                            ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aoeXHZfJj0SJ"
      },
      "outputs": [],
      "source": [
        "answers = df[df.PostTypeId == '2']\n",
        "answers = answers.drop(columns=['PostTypeId'])\n",
        "answers[\"Score\"] = pd.to_numeric(answers[\"Score\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yeb37D9Uj3cE"
      },
      "outputs": [],
      "source": [
        "encode_numeric_zscore(answers, 'Score')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Dk_e7L-wj4cD",
        "outputId": "569bccc5-2103-4d61-dba6-3a5a7223e103"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Score</th>\n",
              "      <th>Body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.701092</td>\n",
              "      <td>&lt;p&gt;\"Backprop\" is the same as \"backpropagation\"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.081593</td>\n",
              "      <td>&lt;p&gt;Noise in the data, to a reasonable amount, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.081593</td>\n",
              "      <td>&lt;p&gt;We typically think of machine learning mode...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.114092</td>\n",
              "      <td>&lt;p&gt;There is no direct way to find the optimal ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>-0.537907</td>\n",
              "      <td>&lt;blockquote&gt;\\n  &lt;p&gt;To put it simply in layman ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374</th>\n",
              "      <td>-0.847657</td>\n",
              "      <td>&lt;blockquote&gt;\\n  &lt;p&gt;\"heavier-than-air flying ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>376</th>\n",
              "      <td>-0.537907</td>\n",
              "      <td>&lt;p&gt;Yes, there were successful attempts at pred...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379</th>\n",
              "      <td>-0.847657</td>\n",
              "      <td>&lt;p&gt;Watson can make its diagnosis based on the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>381</th>\n",
              "      <td>-0.641157</td>\n",
              "      <td>&lt;p&gt;There are a variety of aspects where AI can...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>385</th>\n",
              "      <td>-0.537907</td>\n",
              "      <td>&lt;p&gt;According to IBM Research organization in t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>205 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Score                                               Body\n",
              "2    0.701092  <p>\"Backprop\" is the same as \"backpropagation\"...\n",
              "6    0.081593  <p>Noise in the data, to a reasonable amount, ...\n",
              "8    0.081593  <p>We typically think of machine learning mode...\n",
              "9    1.114092  <p>There is no direct way to find the optimal ...\n",
              "14  -0.537907  <blockquote>\\n  <p>To put it simply in layman ...\n",
              "..        ...                                                ...\n",
              "374 -0.847657  <blockquote>\\n  <p>\"heavier-than-air flying ma...\n",
              "376 -0.537907  <p>Yes, there were successful attempts at pred...\n",
              "379 -0.847657  <p>Watson can make its diagnosis based on the ...\n",
              "381 -0.641157  <p>There are a variety of aspects where AI can...\n",
              "385 -0.537907  <p>According to IBM Research organization in t...\n",
              "\n",
              "[205 rows x 2 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "answers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6oM0OCn315Y"
      },
      "source": [
        "## Load BERT Model\n",
        "### Code from: https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "otgGqwc5lBG0"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "\nTFBertTokenizer requires the tensorflow_text library but it was not found in your environment. You can install it with pip as\nexplained here: https://www.tensorflow.org/text/guide/tf_text_intro.\nPlease note that you may need to restart your runtime after installation.\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32m/Users/clemente/Documents/GitHub/Project-Skynet/BERTFINAL1.ipynb Cell 11\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/clemente/Documents/GitHub/Project-Skynet/BERTFINAL1.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mbert-base-uncased\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/clemente/Documents/GitHub/Project-Skynet/BERTFINAL1.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# creates a TF compatible version\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/clemente/Documents/GitHub/Project-Skynet/BERTFINAL1.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m tf_tokenizer \u001b[39m=\u001b[39m TFBertTokenizer\u001b[39m.\u001b[39;49mfrom_tokenizer(tokenizer)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/clemente/Documents/GitHub/Project-Skynet/BERTFINAL1.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# loads the pre-trained BERT model\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/clemente/Documents/GitHub/Project-Skynet/BERTFINAL1.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model \u001b[39m=\u001b[39m BertModel\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mbert-base-uncased\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/transformers/utils/import_utils.py:1259\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[0;34m(cls, key)\u001b[0m\n\u001b[1;32m   1257\u001b[0m \u001b[39mif\u001b[39;00m key\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_from_config\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1258\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__getattribute__\u001b[39m(key)\n\u001b[0;32m-> 1259\u001b[0m requires_backends(\u001b[39mcls\u001b[39;49m, \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_backends)\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/transformers/utils/import_utils.py:1247\u001b[0m, in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m   1245\u001b[0m failed \u001b[39m=\u001b[39m [msg\u001b[39m.\u001b[39mformat(name) \u001b[39mfor\u001b[39;00m available, msg \u001b[39min\u001b[39;00m checks \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m available()]\n\u001b[1;32m   1246\u001b[0m \u001b[39mif\u001b[39;00m failed:\n\u001b[0;32m-> 1247\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(failed))\n",
            "\u001b[0;31mImportError\u001b[0m: \nTFBertTokenizer requires the tensorflow_text library but it was not found in your environment. You can install it with pip as\nexplained here: https://www.tensorflow.org/text/guide/tf_text_intro.\nPlease note that you may need to restart your runtime after installation.\n"
          ]
        }
      ],
      "source": [
        "# loades a pre-trained BERT tokenizer (text converted to lower case)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "# creates a TF compatible version\n",
        "tf_tokenizer = TFBertTokenizer.from_tokenizer(tokenizer)\n",
        "# loads the pre-trained BERT model\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "YvTjFJAEkn3_"
      },
      "outputs": [],
      "source": [
        "# Tokenize the text in the DataFrame with memory-saving options\n",
        "tokenized_inputs = tokenizer(\n",
        "    list(answers['Body']),\n",
        "    return_tensors=\"pt\",\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    max_length=64\n",
        ")\n",
        "outputs = model(**tokenized_inputs)\n",
        "last_hidden_states = outputs.last_hidden_state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ihjrued535rO"
      },
      "source": [
        "## Prepare data for training"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
